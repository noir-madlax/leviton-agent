from fastapi import FastAPI, Response, Query, Depends, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import asyncio
import json
import logging
from typing import Optional, List
from contextlib import asynccontextmanager
from config import settings
from agent.tools import ProductQueryTool, ReviewQueryTool, get_data_files_status, test_tools
from phoenix.otel import register
from openinference.instrumentation.smolagents import SmolagentsInstrumentor
from product_segmentation.api import router as segmentation_router

# å¯¼å…¥ ORM ç›¸å…³æ¨¡å—
from agent.dependencies import get_product_prompt_service
from core.models.product_prompt import ProductPromptCreate, ProductPromptUpdate, ProductPromptResponse
from agent.services.product_prompt_service import ProductPromptService

# å¯¼å…¥å›¾è¡¨éªŒè¯æœåŠ¡
from agent.services.chart_validation_service import validate_chart_response, chart_validation_service

# é…ç½®æ—¥å¿—
logging.basicConfig(level=getattr(logging, settings.LOG_LEVEL))
logger = logging.getLogger(__name__)

# å¯¼å…¥çˆ¬è™«æ¨¡å—
try:
    from scraping import ScrapingOrchestrator
    SCRAPING_AVAILABLE = True
    logger.info("çˆ¬è™«æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"çˆ¬è™«æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    SCRAPING_AVAILABLE = False

# Agent å’Œå·¥å…·é›†ä¸Šä¸‹æ–‡å°†ç”± lifespan ç®¡ç†
agent = None
init_error = None
tool_collection_context = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ– Agentï¼Œåœ¨å…³é—­æ—¶æ¸…ç†èµ„æºã€‚"""
    global agent, init_error, tool_collection_context

    # åˆå§‹åŒ–ç›‘æ§
    if settings.PHOENIX_ENDPOINT:
        try:
            tracer_provider = register(
                project_name=settings.PROJECT_NAME,
                endpoint=settings.PHOENIX_ENDPOINT
            )
            SmolagentsInstrumentor().instrument(tracer_provider=tracer_provider)
            logger.info(f"Phoenix ç›‘æ§å·²å¯åŠ¨ï¼Œé¡¹ç›®: {settings.PROJECT_NAME}, ç«¯ç‚¹: {settings.PHOENIX_ENDPOINT}")
        except Exception as e:
            logger.error(f"Phoenix ç›‘æ§åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
    else:
        logger.warning("æœªé…ç½® PHOENIX_ENDPOINTï¼ŒPhoenix ç›‘æ§æœªå¯åŠ¨ã€‚")
    
    logger.info("FastAPI åº”ç”¨å¯åŠ¨ï¼Œå¼€å§‹åˆå§‹åŒ– Agent...")
    
    try:
        from smolagents import ToolCollection,ToolCallingAgent, CodeAgent, OpenAIServerModel
        from mcp import StdioServerParameters
        
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {settings.MODEL_ID}")
        model = OpenAIServerModel(
            model_id=settings.MODEL_ID,
            api_base="https://openrouter.ai/api/v1",
            api_key=settings.API_KEY
        )
        
        logger.info("åˆå§‹åŒ–å·¥å…·...")
        product_tool = ProductQueryTool()
        review_tool = ReviewQueryTool()

        server_parameters = StdioServerParameters(
            command="npx",
            args=["-y", 
                  "@supabase/mcp-server-supabase@latest",
                  "--access-token",
                  settings.MCP_ACCESS_TOKEN]
        )

        logger.info("åˆå§‹åŒ– ToolCollection...")
        tool_collection_context = ToolCollection.from_mcp(server_parameters, trust_remote_code=True)
        # æ‰‹åŠ¨è¿›å…¥ä¸Šä¸‹æ–‡
        tool_collection = tool_collection_context.__enter__()

        # all_tools = [product_tool, review_tool, *tool_collection.tools]
        all_tools = [ *tool_collection.tools]

        logger.info("åˆ›å»º CodeAgent...")
        agent = CodeAgent(
            tools=all_tools, 
            model=model,
            max_steps=settings.MAX_ITERATIONS,
            additional_authorized_imports = ['json'],
            final_answer_checks=[check_reasoning_and_plot]
        )

        logger.info(f"Agent åˆå§‹åŒ–æˆåŠŸï¼ŒåŠ è½½çš„å·¥å…·: {agent.tools}")

    except Exception as e:
        init_error = str(e)
        logger.error(f"Agent åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)

    yield

    logger.info("FastAPI åº”ç”¨å…³é—­ï¼Œæ­£åœ¨é‡Šæ”¾èµ„æº...")
    if tool_collection_context:
        try:
            tool_collection_context.__exit__(None, None, None)
            logger.info("å·¥å…·é›†èµ„æºå·²é‡Šæ”¾ã€‚")
        except Exception as e:
            logger.error(f"é‡Šæ”¾å·¥å…·é›†èµ„æºæ—¶å‡ºé”™: {e}", exc_info=True)


app = FastAPI(
    title="Leviton Agent API",
    description="åŸºäº smolagents çš„æ™ºèƒ½ä»£ç† API",
    version="1.0.0",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Register Product Segmentation endpoints
app.include_router(segmentation_router, prefix="/api/segmentation", tags=["Product Segmentation"])

# è¾…åŠ©å‡½æ•°ï¼šè¯»å– prompt æ–‡ä»¶å¹¶æ‹¼æ¥æŸ¥è¯¢
async def prepare_query_with_prompt(query: str) -> str:
    """å‡†å¤‡å®Œæ•´çš„æŸ¥è¯¢ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºè¯"""
    try:
        # ç›´æ¥åˆ›å»ºæœåŠ¡å®ä¾‹ï¼Œä¸ä½¿ç”¨ä¾èµ–æ³¨å…¥
        from core.database.connection import get_supabase_client
        from core.repositories.product_prompt_repository import ProductPromptRepository
        from agent.services.product_prompt_service import ProductPromptService
        
        # è·å– Supabase å®¢æˆ·ç«¯
        supabase_client = get_supabase_client()
        
        # åˆ›å»ºä»“åº“å’ŒæœåŠ¡å®ä¾‹
        repository = ProductPromptRepository(supabase_client)
        service = ProductPromptService(repository)
        
        # è·å–æç¤ºè¯
        prefixPrompt = await service.get_prompt_by_id(5)
        
        if not prefixPrompt:
            logger.warning("æœªæ‰¾åˆ° ID ä¸º 1 çš„æç¤ºè¯ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")
            return query
            
        complete_query = prefixPrompt.prompt + "\n\n ç”¨æˆ·çš„é—®é¢˜å¦‚ä¸‹ï¼š" + query
        
        logger.info(f"å·²æˆåŠŸæ‹¼æ¥æç¤ºè¯ï¼Œæ€» prompt é•¿åº¦: {len(complete_query)} å­—ç¬¦")
        return complete_query
        
    except Exception as e:
        logger.error(f"å‡†å¤‡æŸ¥è¯¢æç¤ºè¯æ—¶å‡ºé”™: {e}")
        logger.info("ä½¿ç”¨åŸå§‹æŸ¥è¯¢ç»§ç»­æ‰§è¡Œ")
        return query


def is_valid_json(text: str) -> bool:
    try:
        json.loads(text)
        return True
    except json.JSONDecodeError:
        return False


def check_reasoning_and_plot(final_answer, agent_memory):
    """
    æ£€æŸ¥æ¨ç†è¿‡ç¨‹å’Œå›¾è¡¨æ˜¯å¦æ­£ç¡®
    
    Args:
        final_answer: LLM ç”Ÿæˆçš„æœ€ç»ˆç­”æ¡ˆ
        agent_memory: Agent çš„å†…å­˜çŠ¶æ€
        
    Returns:
        bool: éªŒè¯æ˜¯å¦é€šè¿‡
    """
    logger.info("å¼€å§‹æ£€æŸ¥æ¨ç†è¿‡ç¨‹å’Œå›¾è¡¨æ˜¯å¦æ­£ç¡®")
    
    # æ£€æŸ¥æ˜¯å¦ä¸º JSON æ ¼å¼
    if not is_valid_json(final_answer):
        logger.info("ç»“æœä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œå°†ä½œä¸ºæ™®é€šå­—ç¬¦ä¸²å¤„ç†")
        return True
    
    logger.info("ç»“æœæˆåŠŸè§£æä¸º JSON æ ¼å¼ï¼Œå¼€å§‹è¿›è¡Œå›¾è¡¨éªŒè¯")
    
    # ä½¿ç”¨å›¾è¡¨éªŒè¯æœåŠ¡è¿›è¡Œå…¨é¢éªŒè¯
    try:
        validation_result = validate_chart_response(final_answer)
        
        # è®°å½•éªŒè¯ç»“æœ
        if validation_result["is_valid_json"]:
            logger.info("âœ… JSON æ ¼å¼éªŒè¯é€šè¿‡")
            
            chart_validation = validation_result.get("chart_validation")
            if chart_validation:
                chart_count = chart_validation.get("chart_count", 0)
                logger.info(f"ğŸ“Š å‘ç° {chart_count} ä¸ªå›¾è¡¨")
                
                if chart_validation["valid"]:
                    logger.info("âœ… æ‰€æœ‰å›¾è¡¨éªŒè¯é€šè¿‡")
                    
                    # è®°å½•è¯¦ç»†ä¿¡æ¯
                    for chart_detail in chart_validation.get("chart_details", []):
                        chart_key = chart_detail["key"]
                        if chart_detail["valid"]:
                            logger.info(f"âœ… {chart_key} éªŒè¯é€šè¿‡")
                            if chart_detail.get("info"):
                                for info in chart_detail["info"]:
                                    logger.info(f"  ğŸ“ˆ {chart_key}: {info}")
                        else:
                            logger.warning(f"âš ï¸ {chart_key} éªŒè¯å­˜åœ¨é—®é¢˜")
                
                else:
                    logger.warning("âš ï¸ éƒ¨åˆ†å›¾è¡¨éªŒè¯å¤±è´¥")
                    for error in chart_validation.get("errors", []):
                        logger.error(f"âŒ å›¾è¡¨éªŒè¯é”™è¯¯: {error}")
                
                # è®°å½•è­¦å‘Šä¿¡æ¯ï¼ˆä¸å½±å“é€šè¿‡çŠ¶æ€ï¼‰
                if chart_validation.get("warnings"):
                    for warning in chart_validation["warnings"]:
                        logger.warning(f"âš ï¸ å›¾è¡¨éªŒè¯è­¦å‘Š: {warning}")
                
                # ç”ŸæˆéªŒè¯æ‘˜è¦
                summary = chart_validation_service.get_validation_summary(validation_result)
                logger.info(f"ğŸ“‹ éªŒè¯æ‘˜è¦: {summary}")
                
                # è¿”å›éªŒè¯ç»“æœ
                return validation_result["overall_valid"]
            
            else:
                logger.error("âŒ å›¾è¡¨éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸")
                return False
        
        else:
            logger.error("âŒ JSON æ ¼å¼éªŒè¯å¤±è´¥")
            if "json_error" in validation_result:
                logger.error(f"JSON è§£æé”™è¯¯: {validation_result['json_error']}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å›¾è¡¨éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}", exc_info=True)
        return False

async def stream_agent_response(query: str):
    """
    è¿è¡Œ smolagents ä»£ç†å¹¶é€šè¿‡ SSE æµå¼è¾“å‡ºç»“æœ
    """
    if not agent:
        if init_error:
            yield f"data: {json.dumps({'error': f'Agent åˆå§‹åŒ–å¤±è´¥: {init_error}'}, ensure_ascii=False)}\n\n"
        else:
            yield f"data: {json.dumps({'error': 'Agent æœªåˆå§‹åŒ–'}, ensure_ascii=False)}\n\n"
        return
    
    try:
        logger.info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")
        
        # å‘é€å¼€å§‹ä¿¡å·
        yield f"data: {json.dumps({'status': 'started', 'message': 'å¼€å§‹å¤„ç†æŸ¥è¯¢...'}, ensure_ascii=False)}\n\n"
        
        try:
            # å‡†å¤‡å®Œæ•´çš„æŸ¥è¯¢ï¼ˆåŒ…å« promptï¼‰
            complete_query = await prepare_query_with_prompt(query)
            
            # è¿è¡Œä»£ç†ä»»åŠ¡ï¼Œè®¾ç½®è¶…æ—¶
            logger.info("æ­£åœ¨è°ƒç”¨ agent.run...")
            result = await asyncio.wait_for(
                asyncio.to_thread(agent.run, complete_query),
                timeout=settings.AGENT_TIMEOUT
            )
            logger.info(f"agent.run æ‰§è¡Œå®Œæˆï¼Œç»“æœç±»å‹: {type(result)}")
            
            # å‘é€è°ƒè¯•ä¿¡æ¯
            yield f"data: {json.dumps({'status': 'debug', 'message': f'agent.run æ‰§è¡Œå®Œæˆï¼Œç»“æœç±»å‹: {type(result).__name__}'}, ensure_ascii=False)}\n\n"
            
        except asyncio.TimeoutError:
            logger.error(f"agent.run æ‰§è¡Œè¶…æ—¶ ({settings.AGENT_TIMEOUT}ç§’)")
            yield f"data: {json.dumps({'status': 'error', 'error': f'Agent æ‰§è¡Œè¶…æ—¶ ({settings.AGENT_TIMEOUT}ç§’)'}, ensure_ascii=False)}\n\n"
            return
        except Exception as agent_error:
            logger.error(f"agent.run æ‰§è¡Œå¤±è´¥: {agent_error}")
            yield f"data: {json.dumps({'status': 'error', 'error': f'Agent æ‰§è¡Œå¤±è´¥: {str(agent_error)}'}, ensure_ascii=False)}\n\n"
            return
        
        # å‘é€è¿›åº¦ä¿¡æ¯
        yield f"data: {json.dumps({'status': 'processing', 'message': 'æ­£åœ¨åˆ†æç»“æœ...'}, ensure_ascii=False)}\n\n"

        # åˆ é™¤ç»“æœä¸­çš„æ¢è¡Œç¬¦ï¼ˆä¸´æ—¶å¤„ç†ï¼‰
        # logger.info(f"å»é™¤æ¢è¡Œç¬¦å‰ result...{result}")
        # result = result.replace("\n", "")
        # logger.info(f"å»é™¤æ¢è¡Œç¬¦å result...{result}")

        # å°†ç»“æœåˆ†å—å‘é€
        if is_valid_json(result):
            logger.info("ç»“æœæˆåŠŸè§£æä¸º JSON æ ¼å¼ï¼ï¼Œç›´æ¥å‘é€ç»“æœ")
            yield f"data: {json.dumps({'status': 'streaming', 'message': str(result)}, ensure_ascii=False)}\n\n"
        elif isinstance(result, str):
            # æŒ‰å¥å·åˆ†å‰²ç»“æœï¼Œæ›´è‡ªç„¶çš„åˆ†å—æ–¹å¼
            sentences = result.split('ã€‚')
            for i, sentence in enumerate(sentences):
                if sentence.strip():
                    chunk_data = {
                        'status': 'streaming',
                        'message': sentence.strip() + ('ã€‚' if i < len(sentences) - 1 else ''),
                        'chunk_index': i
                    }                 
                    yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(settings.STREAM_DELAY)  # æ§åˆ¶æµé€Ÿ
        else:
            # å¦‚æœç»“æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥å‘é€
            yield f"data: {json.dumps({'status': 'streaming', 'message': str(result)}, ensure_ascii=False)}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'status': 'completed', 'message': '[DONE]'}, ensure_ascii=False)}\n\n"
        
    except Exception as e:
        logger.error(f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
        yield f"data: {json.dumps({'status': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å› API ä¿¡æ¯"""
    return {
        "message": "Leviton Agent API",
        "version": "1.0.0",
        "status": "è¿è¡Œä¸­" if agent else "Agent æœªåˆå§‹åŒ–",
        "model_id": settings.MODEL_ID,
        "init_error": init_error if init_error else None,
        "available_tools": agent.tools if agent else []
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "agent_ready": agent is not None,
        "model_id": settings.MODEL_ID,
        "init_error": init_error if init_error else None,
        "data_files_status": get_data_files_status(),
        "config": {
            "host": settings.HOST,
            "port": settings.PORT,
            "debug": settings.DEBUG,
            "max_iterations": settings.MAX_ITERATIONS,
            "agent_timeout": settings.AGENT_TIMEOUT
        }
    }

@app.get("/init-agent")
async def initialize_agent():
    """æ‰‹åŠ¨åˆå§‹åŒ– Agent (å·²å¼ƒç”¨)"""
    return {
        "success": False,
        "message": "Agent åˆå§‹åŒ–å·²ä¸åº”ç”¨ç”Ÿå‘½å‘¨æœŸç»‘å®šï¼Œæ­¤ç«¯ç‚¹å·²å¼ƒç”¨ã€‚",
        "agent_ready": agent is not None,
        "init_error": init_error if init_error else None
    }

@app.get("/test-tools")
async def test_tools_endpoint():
    """æµ‹è¯•å·¥å…·åŠŸèƒ½"""
    return test_tools()

@app.get("/agent-stream")
async def agent_stream(
    query: str = Query(..., description="è¦å¤„ç†çš„æŸ¥è¯¢å†…å®¹", min_length=1)
):
    """
    SSE ç«¯ç‚¹ï¼Œæ¥æ”¶æŸ¥è¯¢å¹¶æµå¼è¿”å› smolagents çš„è¾“å‡º
    """
    if not query.strip():
        return Response(
            content=json.dumps({"error": "æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º"}, ensure_ascii=False),
            status_code=400,
            media_type="application/json"
        )
    
    return StreamingResponse(
        stream_agent_response(query),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
        }
    )

@app.post("/agent-query")
async def agent_query(request: dict):
    """
    POST ç«¯ç‚¹ï¼Œç”¨äºå¤„ç†æ›´å¤æ‚çš„æŸ¥è¯¢è¯·æ±‚
    """
    if not agent:
        return {"error": "Agent æœªåˆå§‹åŒ–", "init_error": init_error}
    
    query = request.get("query", "")
    if not query.strip():
        return {"error": "æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º"}
    
    try:
        # å‡†å¤‡å®Œæ•´çš„æŸ¥è¯¢ï¼ˆåŒ…å« promptï¼‰
        complete_query = await prepare_query_with_prompt(query)
        
        result = await asyncio.to_thread(agent.run, complete_query)
        return {
            "status": "success",
            "query": query,
            "result": result
        }
    except Exception as e:
        logger.error(f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
        return {"error": str(e)}

# ProductPrompt CRUD API ç«¯ç‚¹
@app.get("/prompts", response_model=List[ProductPromptResponse], tags=["æç¤ºè¯ç®¡ç†"])
async def get_all_prompts(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    service: ProductPromptService = Depends(get_product_prompt_service)
):
    """è·å–æ‰€æœ‰æç¤ºè¯ï¼ˆåˆ†é¡µï¼‰"""
    prompts = await service.get_all_prompts(page=page, page_size=page_size)
    return prompts

@app.get("/prompts/{prompt_id}", response_model=ProductPromptResponse, tags=["æç¤ºè¯ç®¡ç†"])
async def get_prompt(
    prompt_id: int,
    service: ProductPromptService = Depends(get_product_prompt_service)
):
    """æ ¹æ® ID è·å–æç¤ºè¯"""
    prompt = await service.get_prompt_by_id(prompt_id)
    if not prompt:
        raise HTTPException(status_code=404, detail="æç¤ºè¯ä¸å­˜åœ¨")
    return prompt

@app.post("/prompts", response_model=ProductPromptResponse, tags=["æç¤ºè¯ç®¡ç†"])
async def create_prompt(
    prompt_data: ProductPromptCreate,
    service: ProductPromptService = Depends(get_product_prompt_service)
):
    """åˆ›å»ºæ–°æç¤ºè¯"""
    prompt = await service.create_prompt(prompt_data)
    if not prompt:
        raise HTTPException(status_code=400, detail="åˆ›å»ºæç¤ºè¯å¤±è´¥")
    return prompt

@app.put("/prompts/{prompt_id}", response_model=ProductPromptResponse, tags=["æç¤ºè¯ç®¡ç†"])
async def update_prompt(
    prompt_id: int,
    prompt_data: ProductPromptUpdate,
    service: ProductPromptService = Depends(get_product_prompt_service)
):
    """æ›´æ–°æç¤ºè¯"""
    prompt = await service.update_prompt(prompt_id, prompt_data)
    if not prompt:
        raise HTTPException(status_code=404, detail="æç¤ºè¯ä¸å­˜åœ¨æˆ–æ›´æ–°å¤±è´¥")
    return prompt

@app.delete("/prompts/{prompt_id}", tags=["æç¤ºè¯ç®¡ç†"])
async def delete_prompt(
    prompt_id: int,
    service: ProductPromptService = Depends(get_product_prompt_service)
):
    """åˆ é™¤æç¤ºè¯"""
    success = await service.delete_prompt(prompt_id)
    if not success:
        raise HTTPException(status_code=404, detail="æç¤ºè¯ä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥")
    return {"message": "æç¤ºè¯åˆ é™¤æˆåŠŸ"}

@app.get("/prompts/search/{search_term}", response_model=List[ProductPromptResponse], tags=["æç¤ºè¯ç®¡ç†"])
async def search_prompts(
    search_term: str,
    search_type: str = Query("prompt", regex="^(prompt|description)$", description="æœç´¢ç±»å‹"),
    limit: int = Query(50, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶"),
    service: ProductPromptService = Depends(get_product_prompt_service)
):
    """æœç´¢æç¤ºè¯"""
    prompts = await service.search_prompts(search_term, search_type, limit)
    return prompts

@app.get("/prompts/recent", response_model=List[ProductPromptResponse], tags=["æç¤ºè¯ç®¡ç†"])
async def get_recent_prompts(
    limit: int = Query(10, ge=1, le=100, description="è¿”å›æ•°é‡"),
    service: ProductPromptService = Depends(get_product_prompt_service)
):
    """è·å–æœ€è¿‘çš„æç¤ºè¯"""
    prompts = await service.get_recent_prompts(limit)
    return prompts

# ===== çˆ¬è™«ç›¸å…³APIæ¥å£ =====

@app.post("/api/scraping/process-url")
async def process_amazon_url(request: dict):
    """
    å¤„ç†Amazon URLï¼Œå¯åŠ¨çˆ¬è™«ä»»åŠ¡
    
    Request body:
        url (str): Amazon URL
        max_products (int): æœ€å¤§äº§å“æ•°é‡ï¼Œé»˜è®¤100
        scrape_reviews (bool): æ˜¯å¦çˆ¬å–è¯„è®ºï¼Œé»˜è®¤true
        review_coverage_months (int): è¯„è®ºè¦†ç›–æœˆæ•°ï¼Œé»˜è®¤6
    """
    if not SCRAPING_AVAILABLE:
        logger.error("çˆ¬è™«æ¨¡å—ä¸å¯ç”¨")
        return {"task_id": "error", "status": "failed", "error": "çˆ¬è™«æ¨¡å—ä¸å¯ç”¨"}
    
    try:
        logger.info(f"æ”¶åˆ°çˆ¬è™«è¯·æ±‚: {request}")
        
        # è§£æè¯·æ±‚å‚æ•°
        url = request.get("url", "").strip()
        max_products = request.get("max_products", 100)
        scrape_reviews = request.get("scrape_reviews", True)
        review_coverage_months = request.get("review_coverage_months", 6)
        
        if not url:
            return {"task_id": "error", "status": "failed", "error": "URL ä¸èƒ½ä¸ºç©º"}
        
        logger.info(f"å¼€å§‹å¤„ç†URL: {url}, max_products: {max_products}")
        
        # ä½¿ç”¨æ–°çš„ç¼–æ’æœåŠ¡
        orchestrator = ScrapingOrchestrator()
        result = await orchestrator.process_url(
            url=url, 
            max_products=max_products,
            scrape_reviews=scrape_reviews,
            review_coverage_months=review_coverage_months
        )
        
        logger.info(f"çˆ¬è™«ä»»åŠ¡å®Œæˆ: {result}")
        return result
        
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return {"task_id": "error", "status": "failed", "error": str(e)}
    except Exception as e:
        logger.error(f"å¤„ç†çˆ¬è™«è¯·æ±‚æ—¶å‡ºé”™: {e}", exc_info=True)
        return {"task_id": "error", "status": "failed", "error": f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}"}

@app.post("/api/scraping/products-only")
async def scrape_products_only(request: dict):
    """
    ä»…çˆ¬å–å•†å“æ•°æ®ï¼ˆä¸åŒ…æ‹¬è¯„è®ºï¼‰
    
    Request body:
        url (str): Amazon URL
        max_products (int): æœ€å¤§äº§å“æ•°é‡ï¼Œé»˜è®¤100
    """
    if not SCRAPING_AVAILABLE:
        return {"error": "çˆ¬è™«æ¨¡å—ä¸å¯ç”¨"}
    
    try:
        url = request.get("url", "").strip()
        max_products = request.get("max_products", 100)
        
        orchestrator = ScrapingOrchestrator()
        result = await orchestrator.scrape_products_only(url, max_products)
        return result
        
    except Exception as e:
        logger.error(f"å¤„ç†å•†å“çˆ¬å–è¯·æ±‚æ—¶å‡ºé”™: {e}", exc_info=True)
        return {"error": f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}"}

@app.post("/api/scraping/reviews-only")
async def scrape_reviews_only(request: dict):
    """
    ä»…çˆ¬å–è¯„è®ºæ•°æ®ï¼ˆå•†å“æ•°æ®å·²å­˜åœ¨ï¼‰
    
    Request body:
        batch_id (int): æ‰¹æ¬¡ID
        review_coverage_months (int): è¯„è®ºè¦†ç›–æœˆæ•°ï¼Œé»˜è®¤6
    """
    if not SCRAPING_AVAILABLE:
        return {"error": "çˆ¬è™«æ¨¡å—ä¸å¯ç”¨"}
    
    try:
        batch_id = request.get("batch_id")
        review_coverage_months = request.get("review_coverage_months", 6)
        
        if not batch_id:
            return {"error": "batch_id is required"}
        
        orchestrator = ScrapingOrchestrator()
        result = await orchestrator.scrape_reviews_only(batch_id, review_coverage_months)
        return result
        
    except Exception as e:
        logger.error(f"å¤„ç†è¯„è®ºçˆ¬å–è¯·æ±‚æ—¶å‡ºé”™: {e}", exc_info=True)
        return {"error": f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}"}

@app.get("/api/scraping/status/{batch_id}")
async def get_scraping_status(batch_id: int):
    """
    è·å–çˆ¬å–çŠ¶æ€
    
    Args:
        batch_id (int): æ‰¹æ¬¡ID
    """
    if not SCRAPING_AVAILABLE:
        return {"error": "çˆ¬è™«æ¨¡å—ä¸å¯ç”¨"}
    
    try:
        orchestrator = ScrapingOrchestrator()
        status = await orchestrator.get_process_status(batch_id=batch_id)
        return status
        
    except Exception as e:
        logger.error(f"è·å–çˆ¬å–çŠ¶æ€æ—¶å‡ºé”™: {e}", exc_info=True)
        return {"error": f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}"}

if __name__ == "__main__":
    import uvicorn
    
    logger.info(f"å‡†å¤‡å¯åŠ¨æœåŠ¡ï¼ŒHOST: {settings.HOST}, PORT: {settings.PORT}")
    logger.info(f"è°ƒè¯•æ¨¡å¼: {settings.DEBUG}")
    
    try:
        uvicorn.run(
            "main:app",
            host=settings.HOST,
            port=settings.PORT,
            reload=settings.DEBUG,
            log_level=settings.LOG_LEVEL.lower()
        )
    except KeyboardInterrupt:
        logger.info("æœåŠ¡è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"å¯åŠ¨æœåŠ¡å¤±è´¥: {e}") 