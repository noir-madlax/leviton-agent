# Scraping 模块设计说明

## 概述
Scraping 模块负责 Amazon 商品和评论数据的爬取与导入，采用模块化设计，支持独立的商品爬取和评论爬取，并提供统一的编排器管理整个流程。

## 核心职责
- **商品爬取**: 从 Amazon 页面爬取商品基本信息
- **评论爬取**: 批量爬取商品评论数据
- **数据导入**: 将爬取的数据标准化后导入数据库
- **流程编排**: 统一管理爬取和导入的完整流程

## 目录结构
```
scraping/
├── products/           # 商品相关
│   ├── scraper.py     # 商品爬取器
│   └── importer.py    # 商品导入器
├── reviews/            # 评论相关
│   ├── scraper.py     # 评论爬取器
│   └── importer.py    # 评论导入器
├── common/            # 通用组件
│   ├── amazon_api.py  # Amazon API 封装
│   └── result_processor.py # 结果处理器
├── data/              # 数据存储
├── orchestrator.py    # 流程编排器
└── __init__.py
```

## 主要组件

### 商品模块 (Products)
- **ProductScraper**: 商品爬取器
  - 支持分类页面和搜索结果页面爬取
  - 自动解析商品基本信息（标题、价格、评分等）
  - 支持分页爬取和数量限制
- **ProductImporter**: 商品导入器
  - 数据清洗和标准化
  - 批量插入数据库
  - 重复数据检测和处理

### 评论模块 (Reviews)
- **ReviewScraper**: 评论爬取器
  - 基于商品ID批量爬取评论
  - 支持时间范围筛选
  - 自动处理分页和反爬限制
- **ReviewImporter**: 评论导入器
  - 评论数据结构化处理
  - 批量导入优化
  - 数据完整性检查

### 通用组件 (Common)
- **AmazonAPI**: Amazon 接口封装
  - 统一的请求处理
  - 反爬策略（随机延时、User-Agent 轮换）
  - 错误重试机制
- **ScrapingResultProcessor**: 结果处理器
  - 数据格式标准化
  - 结果文件管理
  - 状态跟踪

### 编排器 (Orchestrator)
- **ScrapingOrchestrator**: 流程编排器
  - 统一的入口点管理
  - 支持三种工作模式：
    - 完整流程：爬取商品 → 导入商品 → 爬取评论 → 导入评论
    - 仅商品：爬取商品 → 导入商品
    - 仅评论：爬取评论 → 导入评论

## 工作流程

### 完整流程
1. 解析 Amazon URL
2. 爬取商品列表
3. 清洗并导入商品数据
4. 获取商品ID列表
5. 批量爬取商品评论
6. 清洗并导入评论数据

### 数据存储
- **原始数据**: JSON 格式存储在 data/scraped 目录
- **处理后数据**: 通过 Core 模块导入 Supabase 数据库
- **批次管理**: 每次爬取生成唯一批次ID进行追踪

## 技术特性
- **异步处理**: 基于 asyncio 的异步爬取
- **错误恢复**: 支持断点续传和失败重试
- **限流控制**: 自动控制请求频率，避免被封
- **数据去重**: 自动检测和处理重复数据

## 扩展说明
- **新增平台**: 在 common 目录添加新的 API 封装
- **自定义处理**: 继承 Scraper 和 Importer 基类
- **监控集成**: 通过编排器状态接口进行监控 